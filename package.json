{
  "name": "ollama-autopilot",
  "displayName": "Ollama Autopilot - Local LLM Autocomplete",
  "publisher": "dadul96",
  "author": {
	  "name": "dadul96"
  },
  "icon": "images/ollama_autopilot_logo.png",
  "description": "Local LLM code autocomplete for VS Code powered by Ollama. Inline AI code completion - fully offline, no API keys, no cloud.",
  "version": "1.0.0",
  "repository": {
    "type": "git",
    "url": "https://github.com/dadul96/ollama-autopilot"
  },
  "engines": {
    "vscode": "^1.85.0"
  },
  "categories": [
    "AI",
    "Other"
  ],
  "keywords": [
  "ollama",
  "ollama vscode",
  "ollama autocomplete",
  "local llm",
  "local ai",
  "offline ai",
  "code completion",
  "inline completion",
  "copilot alternative",
  "github copilot alternative",
  "ai autocomplete",
  "llm autocomplete",
  "vs code ai",
  "open source copilot"
  ],
  "license": "MIT",
  "activationEvents": ["onLanguage"],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "ollama-autopilot.showMenu",
        "title": "Ollama Autopilot: Show Menu"
      },
      {
        "command": "ollama-autopilot.enable",
        "title": "Ollama Autopilot: Enable"
      },
      {
        "command": "ollama-autopilot.disable",
        "title": "Ollama Autopilot: Disable"
      },
      {
        "command": "ollama-autopilot.snooze",
        "title": "Ollama Autopilot: Snooze"
      },
      {
        "command": "ollama-autopilot.selectModel",
        "title": "Ollama Autopilot: Select Model"
      }
    ],
    "configuration": {
      "title": "Ollama Autopilot",
      "properties": {
        "ollama-autopilot.general.autopilotEnabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable or disable Ollama Autopilot",
          "order": 1
        },
        "ollama-autopilot.general.baseUrl": {
          "type": "string",
          "default": "http://localhost:11434",
          "description": "Ollama API Base URL",
          "order": 2
        },
        "ollama-autopilot.general.autocompleteDelayMs": {
          "type": "number",
          "default": 500,
          "minimum": 0,
          "maximum": 60000,
          "description": "Delay in milliseconds before triggering autocomplete",
          "order": 3
        },
        "ollama-autopilot.general.snoozeTimeMin": {
          "type": "number",
          "default": 5,
          "minimum": 0,
          "maximum": 1440,
          "description": "Time in minutes the Ollama Autopilot will snooze its autocomplete before resuming",
          "order": 4
        },
        "ollama-autopilot.model.modelName": {
          "type": "string",
          "default": "deepseek-coder-v2:16b",
          "description": "Ollama model name",
          "order": 5
        },
        "ollama-autopilot.model.maxAutocompleteTokens": {
          "type": "number",
          "default": 100,
          "minimum": 1,
          "maximum": 131072,
          "description": "Maximum number of tokens for autocomplete",
          "order": 6
        },
        "ollama-autopilot.model.temperature": {
          "type": "number",
          "default": 0.1,
          "minimum": 0,
          "maximum": 1,
          "description": "Model temperature (typical range 0-0.4)",
          "order": 7
        },
          "ollama-autopilot.model.modelKeepAliveTimeMin": {
          "type": "number",
          "default": 10,
          "minimum": -1,
          "maximum": 1440,
          "description": "Time in minutes the model should remain loaded in memory (use -1 for unlimited)",
          "order": 9
        },
          "ollama-autopilot.prompt.textBeforeCursorSize": {
          "type": "number",
          "default": 2048,
          "minimum": 0,
          "maximum": 131072,
          "description": "Number of text characters before the cursor that should be considered (keep your models context size in mind)",
          "order": 10
        },
        "ollama-autopilot.prompt.textAfterCursorSize": {
          "type": "number",
          "default": 0,
          "minimum": 0,
          "maximum": 131072,
          "description": "Number of text characters after the cursor that should be considered (keep your models context size in mind; default prompt does not use this)",
          "order": 11
        },
          "ollama-autopilot.prompt.promptText": {
          "type": "string",
          "editPresentation": "multilineText",
          "default": "You are an inline code completion engine. \nContinue the following ${languageId} code exactly as a developer would type next. \n \nRules: \n- Output only the code continuation \n- Do not repeat or modify existing code \n- Do not add comments, imports, or explanations \n- Match the existing style, formatting, and indentation \n- Keep the completion short and stop early \n \nExisting code: \n${textBeforeCursor}",
          "description": "Prompt text. You can use the following template literals in your prompt: ${workspaceName}, ${fileName}, ${languageId}, ${textBeforeCursor}, ${textAfterCursor}",
          "order": 12
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "npm run compile && npm run lint",
    "lint": "eslint src",
    "test": "vscode-test"
  },
  "devDependencies": {
    "@types/vscode": "1.85.0",
    "@types/mocha": "^10.0.10",
    "@types/node": "18.x",
    "typescript-eslint": "^8.52.0",
    "eslint": "^9.39.2",
    "typescript": "^5.9.3",
    "@vscode/test-cli": "^0.0.12",
    "@vscode/test-electron": "^2.5.2"
  }
}
